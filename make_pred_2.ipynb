{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model on the `test set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter here the name of the file with the `test set` (the file must be in the folder `data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (637774, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15673/3588360752.py:4: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(path / filename)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "def load_ds(path: Path, filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Read the dataset csv file as a pandas dataframe.\"\"\"\n",
    "    return pd.read_csv(path / filename)\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = Path().absolute() / \"data\"\n",
    "X_y_test = load_ds(dataset_path, filename)\n",
    "\n",
    "print(f\"Shape: {X_y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.read_csv('data/store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_test = X_y_test.merge(store, on=\"Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_test = X_y_test.loc[~X_y_test.Sales.isna(), :]\n",
    "X_y_test = X_y_test.loc[X_y_test.Sales != 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape X_train: (497376, 17)\n",
      "shape y_train: (497376,)\n"
     ]
    }
   ],
   "source": [
    "X_test = X_y_test.drop([\"Sales\"], axis=1)\n",
    "y_test = X_y_test.loc[:, \"Sales\"].copy()\n",
    "\n",
    "print(f\"shape X_train: {X_test.shape}\")\n",
    "print(f\"shape y_train: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TransformerMixin: add method \".fit_transform()\"\n",
    "# BaseEstimator: add methods \".get_params()\" and \".set_params()\"\n",
    "# We need 3 methods:\n",
    "# 1) .fit()\n",
    "# 2) .transform()\n",
    "# 3) .fit_transform() (provided by \"TransformerMixin\")\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    # avoid \"*args\" or \"**kargs\" in \"__init__\"\n",
    "    def __init__(self):\n",
    "        self.mean_Month = pd.DataFrame()\n",
    "        self.mean_Store = pd.DataFrame()\n",
    "        self.mean_DayOfWeek = pd.DataFrame()\n",
    "        self.mean_Promo_Store = pd.DataFrame()\n",
    "\n",
    "    # fit is needed later for the pipilene\n",
    "    def fit(self, X, y=None):\n",
    "        # X[\"target_var\"] = y\n",
    "\n",
    "        # Date\n",
    "        #self.means[col] = X.groupby(col, dropna=False)['Sales'].mean().rename(col + 'Mean')\n",
    "        Date_2 = pd.to_datetime(X[\"Date\"], format=\"%Y-%m-%d\")\n",
    "        X[\"Month\"] = Date_2.dt.month\n",
    "        #print(X.columns)\n",
    "        self.mean_Month = self.mean_encode(X, \"Month\", \"Sales\")\n",
    "        #\n",
    "        ## self.mean_Month = (\n",
    "        ##     # select columns\n",
    "        ##     X.loc[:, [\"Month\", \"Sales\"]]\n",
    "        ##     # group by feature\n",
    "        ##     .groupby(\"Month\")\n",
    "        ##     # aggregate over feature using target mean\n",
    "        ##     .agg(Month_mean=(\"Sales\", np.mean))\n",
    "        ##     # index (i.e., feature categories) as a column\n",
    "        ##     .reset_index()\n",
    "        ##     # rename the column with the aggregated means\n",
    "        ##     #.rename(columns={\"tmp_name\":new_col_name})\n",
    "        ## )\n",
    "        #print(self.mean_Month)\n",
    "\n",
    "        # Store\n",
    "        self.mean_Store = self.mean_encode(X, \"Store\", \"Sales\")\n",
    "\n",
    "        # DayOfWeek\n",
    "        self.mean_DayOfWeek = self.mean_encode(X, \"DayOfWeek\", \"Sales\")\n",
    "\n",
    "        # Promo (separately for each Store)\n",
    "        self.mean_Promo_Store = self.mean_encode_2(X, \"Promo\", \"Store\", \"Sales\")\n",
    "\n",
    "        # Drop the target\n",
    "        #target_to_drop = [\"Sales\"]\n",
    "        #X.drop(columns=target_to_drop, inplace=True)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Since I use MEAN ENCODING, \"X\" must include\n",
    "        # the terget variable. Below, just before returning\n",
    "        # the transformed X, the target variable is dropped.\n",
    "\n",
    "        # Date\n",
    "        Date_2 = pd.to_datetime(X[\"Date\"], format=\"%Y-%m-%d\")\n",
    "        X[\"Month\"] = Date_2.dt.month\n",
    "        X = pd.merge(X, self.mean_Month, how=\"left\", on=\"Month\")\n",
    "        # drop: \"Date\" and \"Month\"\n",
    "\n",
    "        # Store\n",
    "        #X = self.mean_encode(X, \"Store\", \"Sales\")\n",
    "        X = pd.merge(X, self.mean_Store, how=\"left\", on=\"Store\")\n",
    "        # drop: \"Store\"\n",
    "\n",
    "        # DayOfWeek\n",
    "        # X = self.mean_encode(X, \"DayOfWeek\", \"Sales\")\n",
    "        X = pd.merge(X, self.mean_DayOfWeek, how=\"left\", on=\"DayOfWeek\")\n",
    "        # drop: \"DayOfWeek\"\n",
    "\n",
    "        # Promo (separately for each Store)\n",
    "        # X = self.mean_encode_2(X, \"Promo\", \"Store\", \"Sales\")\n",
    "        X = pd.merge(X, self.mean_Promo_Store, how=\"left\", on=[\"Promo\", \"Store\"])\n",
    "        # drop: \"Promo\" and \"Store\"\n",
    "\n",
    "        # SchoolHoliday\n",
    "        X.loc[X.SchoolHoliday==\"0\", :] = 0.0\n",
    "        # keep: \"SchoolHoliday\"\n",
    "\n",
    "        # StoreType: keep, no transformation\n",
    "\n",
    "        # Assortment: keep, no transformation\n",
    "\n",
    "        # Promo2: keep, no transformation\n",
    "\n",
    "        # CompetitionDistance\n",
    "        nb = 10 # number of bins\n",
    "        clip_upper = 10000\n",
    "        X[\"CD_clip\"] = X[\"CompetitionDistance\"].clip(upper=clip_upper)\n",
    "        CD_clip_bins = pd.cut(\n",
    "            X[\"CD_clip\"],\n",
    "            bins=nb,\n",
    "            labels=[i for i in range(nb)])\n",
    "        X['CD_clip_bins'] = pd.to_numeric(CD_clip_bins)\n",
    "        X[\"CD_clip_bins_clip\"] = X[\"CD_clip_bins\"].clip(upper=clip_upper) # \n",
    "        # drop: \"CompetitionDistance\", \"CD_clip\", \"CD_clip_bins\"\n",
    "\n",
    "        # Drop unused columns\n",
    "        cols_to_drop = [\n",
    "            \"Date\", \"Month\", \"Store\", \"DayOfWeek\", \"Customers\", \"Open\", \"Promo\",\n",
    "            \"StateHoliday\", \"CompetitionDistance\", \"CD_clip\", \"CD_clip_bins\",\n",
    "            \"CompetitionOpenSinceMonth\", \"CompetitionOpenSinceYear\", \"Promo2SinceWeek\",\n",
    "            \"Promo2SinceYear\", \"PromoInterval\"]\n",
    "        X.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "        # Drop the target\n",
    "        with_target = sum([col == \"Sales\" for col in X.columns])\n",
    "        if with_target > 0:\n",
    "            target_to_drop = [\"Sales\"]\n",
    "            X.drop(columns=target_to_drop, inplace=True)\n",
    "\n",
    "        return X\n",
    "    \n",
    "\n",
    "    def mean_encode(self, df: pd.DataFrame, feature: str, target: str):\n",
    "        \"\"\"\n",
    "        df: dataframe with \"feature\" and \"target\" columns\n",
    "        feature: feature to transform\n",
    "        target: target variable\n",
    "        \"\"\"\n",
    "        new_col_name = feature + \"_mean\"\n",
    "        df_enc = (\n",
    "            # select columns\n",
    "            df.loc[:, [feature, target]]\n",
    "            # group by feature\n",
    "            .groupby(feature)\n",
    "            # aggregate over feature using target mean\n",
    "            .agg(tmp_name=(target, np.mean))\n",
    "            # index (i.e., feature categories) as a column\n",
    "            .reset_index()\n",
    "            # rename the column with the aggregated means\n",
    "            .rename(columns={\"tmp_name\":new_col_name})\n",
    "        )\n",
    "    \n",
    "        # merge: add the new column with the aggregated mean from\n",
    "        # \"df_enc\" back into \"df\"\n",
    "        # df_merged = pd.merge(df, df_enc, how=\"left\", on=feature)\n",
    "    \n",
    "        return df_enc # df_merged\n",
    "        \n",
    "        \n",
    "    def mean_encode_2(self, df: pd.DataFrame, feature1: str, feature2: str, target: str):\n",
    "        \"\"\"\n",
    "        Same as \"mean_encode\" but with 2 features.\n",
    "        df: dataframe with \"feature\" and \"target\" columns\n",
    "        feature: feature to transform\n",
    "        target: target variable\n",
    "        \"\"\"\n",
    "        new_col_name = feature1 + feature2 + \"_mean\"\n",
    "        df_enc = (\n",
    "            # select columns\n",
    "            df.loc[:, [feature1, feature2, target]]\n",
    "            # group by feature\n",
    "            .groupby([feature1, feature2])\n",
    "            # aggregate over feature using target mean\n",
    "            .agg(tmp_name = (target, np.mean))\n",
    "            # index (i.e., feature categories) as a column\n",
    "            .reset_index()\n",
    "            # rename the column with the aggregated means\n",
    "            .rename(columns={\"tmp_name\":new_col_name})\n",
    "            )\n",
    "    \n",
    "        # merge: add the new column with the aggregated mean from\n",
    "        # \"df_enc\" back into \"df\"\n",
    "        # df_merged = pd.merge(df, df_enc, how=\"left\", on=[feature1, feature2])\n",
    "    \n",
    "        return df_enc # df_merged\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = load(\"models/random_forest_final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(preds, actuals):\n",
    "    assert preds.shape == actuals.shape\n",
    "    return 100 * np.linalg.norm((actuals - preds) / actuals) / np.sqrt(preds.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.251948432052366"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric(y_pred, np.array(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
