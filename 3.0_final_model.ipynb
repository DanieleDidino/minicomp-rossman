{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model on the `test set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (99476, 18)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "def load_ds(path: Path, filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Read the dataset csv file as a pandas dataframe.\"\"\"\n",
    "    return pd.read_csv(path / filename)\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = Path().absolute() / \"data\"\n",
    "filename = \"X_y_test.csv\"\n",
    "X_y_test = load_ds(dataset_path, filename)\n",
    "\n",
    "print(f\"Shape: {X_y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_y_test # include \"Sales\", CombinedAttributesAdder() drops it\n",
    "y_test = X_y_test.loc[:, \"Sales\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TransformerMixin: add method \".fit_transform()\"\n",
    "# BaseEstimator: add methods \".get_params()\" and \".set_params()\"\n",
    "# We need 3 methods:\n",
    "# 1) .fit()\n",
    "# 2) .transform()\n",
    "# 3) .fit_transform() (provided by \"TransformerMixin\")\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    # avoid \"*args\" or \"**kargs\" in \"__init__\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # fit is needed later for the pipilene\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Since I use MEAN ENCODING, \"X\" must include\n",
    "        # the terget variable. Below, just before returning\n",
    "        # the transformed X, the target variable is dropped.\n",
    "\n",
    "        # Date\n",
    "        Date_2 = pd.to_datetime(X[\"Date\"], format=\"%Y-%m-%d\")\n",
    "        X[\"Month\"] = Date_2.dt.month\n",
    "        X = mean_encode(X, \"Month\", \"Sales\")\n",
    "        # drop: \"Date\" and \"Month\"\n",
    "\n",
    "        # Store\n",
    "        X = mean_encode(X, \"Store\", \"Sales\")\n",
    "        # drop: \"Store\"\n",
    "\n",
    "        # DayOfWeek\n",
    "        X = mean_encode(X, \"DayOfWeek\", \"Sales\")\n",
    "        # drop: \"DayOfWeek\"\n",
    "\n",
    "        # Promo (separately for each Store)\n",
    "        X = mean_encode_2(X, \"Promo\", \"Store\", \"Sales\")\n",
    "        # drop: \"Promo\" and \"Store\"\n",
    "\n",
    "        # SchoolHoliday\n",
    "        X.loc[X.SchoolHoliday==\"0\", :] = 0.0\n",
    "        # keep: \"SchoolHoliday\"\n",
    "\n",
    "        # StoreType: keep, no transformation\n",
    "\n",
    "        # Assortment: keep, no transformation\n",
    "\n",
    "        # Promo2: keep, no transformation\n",
    "\n",
    "        # CompetitionDistance\n",
    "        nb = 10 # number of bins\n",
    "        clip_upper = 10000\n",
    "        X[\"CD_clip\"] = X[\"CompetitionDistance\"].clip(upper=clip_upper)\n",
    "        CD_clip_bins = pd.cut(\n",
    "            X[\"CD_clip\"],\n",
    "            bins=nb,\n",
    "            labels=[i for i in range(nb)])\n",
    "        X['CD_clip_bins'] = pd.to_numeric(CD_clip_bins)\n",
    "        X[\"CD_clip_bins_clip\"] = X[\"CD_clip_bins\"].clip(upper=clip_upper) # \n",
    "        # drop: \"CompetitionDistance\", \"CD_clip\", \"CD_clip_bins\"\n",
    "\n",
    "        # Drop unused columns\n",
    "        cols_to_drop = [\n",
    "            \"Date\", \"Month\", \"Store\", \"DayOfWeek\", \"Customers\", \"Open\", \"Promo\",\n",
    "            \"StateHoliday\", \"CompetitionDistance\", \"CD_clip\", \"CD_clip_bins\",\n",
    "            \"CompetitionOpenSinceMonth\", \"CompetitionOpenSinceYear\", \"Promo2SinceWeek\",\n",
    "            \"Promo2SinceYear\", \"PromoInterval\"]\n",
    "        X.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "        # Drop the target\n",
    "        target_to_drop = [\"Sales\"]\n",
    "        X.drop(columns=target_to_drop, inplace=True)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = load(\"models/GridSearch_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# open a file, where you stored the pickled data\n",
    "file = open(\"models/GridSearch_2\", 'rb')\n",
    "\n",
    "# dump information to that file\n",
    "mod = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'prediction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mod\u001b[39m.\u001b[39;49mprediction(X_train)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'prediction'"
     ]
    }
   ],
   "source": [
    "mod.prediction(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_encode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mod\u001b[39m.\u001b[39;49mbest_estimator_\u001b[39m.\u001b[39;49mpredict(X_test)\n",
      "File \u001b[0;32m~/Desktop/Projects/minicomp-rossman/.venv/lib/python3.10/site-packages/sklearn/pipeline.py:507\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    505\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[1;32m    506\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 507\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[1;32m    508\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m~/Desktop/Projects/minicomp-rossman/.venv/lib/python3.10/site-packages/sklearn/pipeline.py:689\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    687\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[1;32m    688\u001b[0m \u001b[39mfor\u001b[39;00m _, _, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter():\n\u001b[0;32m--> 689\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[1;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m Xt\n",
      "File \u001b[0;32m~/Desktop/Projects/minicomp-rossman/.venv/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36mCombinedAttributesAdder.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     22\u001b[0m Date_2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(X[\u001b[39m\"\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m X[\u001b[39m\"\u001b[39m\u001b[39mMonth\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m Date_2\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mmonth\n\u001b[0;32m---> 24\u001b[0m X \u001b[39m=\u001b[39m mean_encode(X, \u001b[39m\"\u001b[39m\u001b[39mMonth\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSales\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[39m# drop: \"Date\" and \"Month\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[39m# Store\u001b[39;00m\n\u001b[1;32m     28\u001b[0m X \u001b[39m=\u001b[39m mean_encode(X, \u001b[39m\"\u001b[39m\u001b[39mStore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSales\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_encode' is not defined"
     ]
    }
   ],
   "source": [
    "mod.best_estimator_.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
