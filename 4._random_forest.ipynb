{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melbourne Housing Market\n",
    "\n",
    "House Prices Prediction\n",
    "\n",
    "The data is from Kaggle and can be found [here](https://www.kaggle.com/anthonypino/melbourne-housing-market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_others(df: pd.DataFrame, feature: str, N_counts: int):\n",
    "    \"\"\"\n",
    "    df: data frame\n",
    "    feature: feature to transform\n",
    "    N_counts: categories with less than \"N_counts\" counts are converted to \"others\" \n",
    "    \"\"\"\n",
    "\n",
    "    df_count = (\n",
    "        df\n",
    "        .groupby(feature)[feature]\n",
    "        .value_counts()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Select the categories with less than N_counts\n",
    "    df_other = df_count.loc[df_count[\"count\"] < N_counts, feature]\n",
    "\n",
    "    # Name for the new column with some categories converted to \"others\"\n",
    "    new_col_name = feature + \"_others\"\n",
    "\n",
    "    # Copy original column\n",
    "    df[new_col_name] = df[feature]\n",
    "    # Categories with less than \"N_counts\" counts (this info is #\n",
    "    # stored in the data frame \"df_other\") are set to \"others\"\n",
    "    df.loc[df[feature].isin(df_other), [new_col_name]] = \"others\"\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def metric(preds, actuals):\n",
    "    preds = preds.reshape(-1)\n",
    "    actuals = actuals.reshape(-1)\n",
    "    assert preds.shape == actuals.shape\n",
    "    return 100 * np.linalg.norm((actuals - preds) / actuals) / np.sqrt(preds.shape[0])\n",
    "\n",
    "\n",
    "def RMSPE(y, y_pred):\n",
    "     rmspe = np.sum(((y - y_pred) / y)**2) / len(y)\n",
    "     return rmspe\n",
    "\n",
    "\n",
    "def print_best_model_metrics(gs, X, y):\n",
    "    \"\"\"\"\n",
    "    gs: fitted GridSearch object\n",
    "    X: DataFrame with features\n",
    "    y: actual target\n",
    "    \"\"\"\n",
    "    print(f\"Best parameters:\\n{gs.best_params_}\")\n",
    "    print(f\"\\nBest score: {gs.best_score_:.3f}\")\n",
    "    print(f\"RMSE: {np.sqrt(-1*gs.best_score_):.3f}\")\n",
    "    score = gs.score(X, y)\n",
    "    print(f\"\\nneg_mean_squared_error on the full train set: {score:.3f}\")\n",
    "    print(f\"RMSE on the full train set: {np.sqrt(-1*score):.3f}\")\n",
    "    y_pred = gs.predict(X)\n",
    "    print(f\"\\nMean squared error = {mean_squared_error(y, y_pred, squared=False):.2f}\")\n",
    "    print(f\"Root Mean Square Percentage Error: {RMSPE(y, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (397900, 18)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "def load_ds(path: Path, filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Read the dataset csv file as a pandas dataframe.\"\"\"\n",
    "    return pd.read_csv(path / filename)\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = Path().absolute() / \"data\"\n",
    "filename = \"X_y_train.csv\"\n",
    "X_y_train = load_ds(dataset_path, filename)\n",
    "\n",
    "print(f\"Shape: {X_y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 397900 entries, 0 to 397899\n",
      "Data columns (total 18 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   Date                       397900 non-null  object \n",
      " 1   Store                      397900 non-null  float64\n",
      " 2   DayOfWeek                  386039 non-null  float64\n",
      " 3   Sales                      397900 non-null  float64\n",
      " 4   Customers                  386030 non-null  float64\n",
      " 5   Open                       385880 non-null  float64\n",
      " 6   Promo                      386000 non-null  float64\n",
      " 7   StateHoliday               385848 non-null  object \n",
      " 8   SchoolHoliday              385817 non-null  float64\n",
      " 9   StoreType                  397900 non-null  object \n",
      " 10  Assortment                 397900 non-null  object \n",
      " 11  CompetitionDistance        396864 non-null  float64\n",
      " 12  CompetitionOpenSinceMonth  271565 non-null  float64\n",
      " 13  CompetitionOpenSinceYear   271565 non-null  float64\n",
      " 14  Promo2                     397900 non-null  int64  \n",
      " 15  Promo2SinceWeek            201914 non-null  float64\n",
      " 16  Promo2SinceYear            201914 non-null  float64\n",
      " 17  PromoInterval              201914 non-null  object \n",
      "dtypes: float64(12), int64(1), object(5)\n",
      "memory usage: 54.6+ MB\n"
     ]
    }
   ],
   "source": [
    "X_y_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Jonathan\n",
    "\n",
    "class MeanEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.means = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.columns:\n",
    "            self.means[col] = X.groupby(col, dropna=False)['Sales'].mean().rename(col + 'Mean')\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            X = X.merge(self.means[col], on=col)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TransformerMixin: add method \".fit_transform()\"\n",
    "# BaseEstimator: add methods \".get_params()\" and \".set_params()\"\n",
    "# We need 3 methods:\n",
    "# 1) .fit()\n",
    "# 2) .transform()\n",
    "# 3) .fit_transform() (provided by \"TransformerMixin\")\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    # avoid \"*args\" or \"**kargs\" in \"__init__\"\n",
    "    def __init__(self):\n",
    "        self.mean_Month = pd.DataFrame()\n",
    "        self.mean_Store = pd.DataFrame()\n",
    "        self.mean_DayOfWeek = pd.DataFrame()\n",
    "        self.mean_Promo_Store = pd.DataFrame()\n",
    "\n",
    "    # fit is needed later for the pipilene\n",
    "    def fit(self, X, y=None):\n",
    "        # X[\"target_var\"] = y\n",
    "\n",
    "        # Date\n",
    "        #self.means[col] = X.groupby(col, dropna=False)['Sales'].mean().rename(col + 'Mean')\n",
    "        Date_2 = pd.to_datetime(X[\"Date\"], format=\"%Y-%m-%d\")\n",
    "        X[\"Month\"] = Date_2.dt.month\n",
    "        #print(X.columns)\n",
    "        self.mean_Month = self.mean_encode(X, \"Month\", \"Sales\")\n",
    "        #\n",
    "        ## self.mean_Month = (\n",
    "        ##     # select columns\n",
    "        ##     X.loc[:, [\"Month\", \"Sales\"]]\n",
    "        ##     # group by feature\n",
    "        ##     .groupby(\"Month\")\n",
    "        ##     # aggregate over feature using target mean\n",
    "        ##     .agg(Month_mean=(\"Sales\", np.mean))\n",
    "        ##     # index (i.e., feature categories) as a column\n",
    "        ##     .reset_index()\n",
    "        ##     # rename the column with the aggregated means\n",
    "        ##     #.rename(columns={\"tmp_name\":new_col_name})\n",
    "        ## )\n",
    "        #print(self.mean_Month)\n",
    "\n",
    "        # Store\n",
    "        self.mean_Store = self.mean_encode(X, \"Store\", \"Sales\")\n",
    "\n",
    "        # DayOfWeek\n",
    "        self.mean_DayOfWeek = self.mean_encode(X, \"DayOfWeek\", \"Sales\")\n",
    "\n",
    "        # Promo (separately for each Store)\n",
    "        self.mean_Promo_Store = self.mean_encode_2(X, \"Promo\", \"Store\", \"Sales\")\n",
    "\n",
    "        # Drop the target\n",
    "        #target_to_drop = [\"Sales\"]\n",
    "        #X.drop(columns=target_to_drop, inplace=True)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Since I use MEAN ENCODING, \"X\" must include\n",
    "        # the terget variable. Below, just before returning\n",
    "        # the transformed X, the target variable is dropped.\n",
    "\n",
    "        # Date\n",
    "        Date_2 = pd.to_datetime(X[\"Date\"], format=\"%Y-%m-%d\")\n",
    "        X[\"Month\"] = Date_2.dt.month\n",
    "        X = pd.merge(X, self.mean_Month, how=\"left\", on=\"Month\")\n",
    "        # drop: \"Date\" and \"Month\"\n",
    "\n",
    "        # Store\n",
    "        #X = self.mean_encode(X, \"Store\", \"Sales\")\n",
    "        X = pd.merge(X, self.mean_Store, how=\"left\", on=\"Store\")\n",
    "        # drop: \"Store\"\n",
    "\n",
    "        # DayOfWeek\n",
    "        # X = self.mean_encode(X, \"DayOfWeek\", \"Sales\")\n",
    "        X = pd.merge(X, self.mean_DayOfWeek, how=\"left\", on=\"DayOfWeek\")\n",
    "        # drop: \"DayOfWeek\"\n",
    "\n",
    "        # Promo (separately for each Store)\n",
    "        # X = self.mean_encode_2(X, \"Promo\", \"Store\", \"Sales\")\n",
    "        X = pd.merge(X, self.mean_Promo_Store, how=\"left\", on=[\"Promo\", \"Store\"])\n",
    "        # drop: \"Promo\" and \"Store\"\n",
    "\n",
    "        # SchoolHoliday\n",
    "        X.loc[X.SchoolHoliday==\"0\", :] = 0.0\n",
    "        # keep: \"SchoolHoliday\"\n",
    "\n",
    "        # StoreType: keep, no transformation\n",
    "\n",
    "        # Assortment: keep, no transformation\n",
    "\n",
    "        # Promo2: keep, no transformation\n",
    "\n",
    "        # CompetitionDistance\n",
    "        nb = 10 # number of bins\n",
    "        clip_upper = 10000\n",
    "        X[\"CD_clip\"] = X[\"CompetitionDistance\"].clip(upper=clip_upper)\n",
    "        CD_clip_bins = pd.cut(\n",
    "            X[\"CD_clip\"],\n",
    "            bins=nb,\n",
    "            labels=[i for i in range(nb)])\n",
    "        X['CD_clip_bins'] = pd.to_numeric(CD_clip_bins)\n",
    "        X[\"CD_clip_bins_clip\"] = X[\"CD_clip_bins\"].clip(upper=clip_upper) # \n",
    "        # drop: \"CompetitionDistance\", \"CD_clip\", \"CD_clip_bins\"\n",
    "\n",
    "        # Drop unused columns\n",
    "        cols_to_drop = [\n",
    "            \"Date\", \"Month\", \"Store\", \"DayOfWeek\", \"Customers\", \"Open\", \"Promo\",\n",
    "            \"StateHoliday\", \"CompetitionDistance\", \"CD_clip\", \"CD_clip_bins\",\n",
    "            \"CompetitionOpenSinceMonth\", \"CompetitionOpenSinceYear\", \"Promo2SinceWeek\",\n",
    "            \"Promo2SinceYear\", \"PromoInterval\"]\n",
    "        X.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "        # Drop the target\n",
    "        with_target = sum([col == \"Sales\" for col in X.columns])\n",
    "        if with_target > 0:\n",
    "            target_to_drop = [\"Sales\"]\n",
    "            X.drop(columns=target_to_drop, inplace=True)\n",
    "\n",
    "        return X\n",
    "    \n",
    "\n",
    "    def mean_encode(self, df: pd.DataFrame, feature: str, target: str):\n",
    "        \"\"\"\n",
    "        df: dataframe with \"feature\" and \"target\" columns\n",
    "        feature: feature to transform\n",
    "        target: target variable\n",
    "        \"\"\"\n",
    "        new_col_name = feature + \"_mean\"\n",
    "        df_enc = (\n",
    "            # select columns\n",
    "            df.loc[:, [feature, target]]\n",
    "            # group by feature\n",
    "            .groupby(feature)\n",
    "            # aggregate over feature using target mean\n",
    "            .agg(tmp_name=(target, np.mean))\n",
    "            # index (i.e., feature categories) as a column\n",
    "            .reset_index()\n",
    "            # rename the column with the aggregated means\n",
    "            .rename(columns={\"tmp_name\":new_col_name})\n",
    "        )\n",
    "    \n",
    "        # merge: add the new column with the aggregated mean from\n",
    "        # \"df_enc\" back into \"df\"\n",
    "        # df_merged = pd.merge(df, df_enc, how=\"left\", on=feature)\n",
    "    \n",
    "        return df_enc # df_merged\n",
    "        \n",
    "        \n",
    "    def mean_encode_2(self, df: pd.DataFrame, feature1: str, feature2: str, target: str):\n",
    "        \"\"\"\n",
    "        Same as \"mean_encode\" but with 2 features.\n",
    "        df: dataframe with \"feature\" and \"target\" columns\n",
    "        feature: feature to transform\n",
    "        target: target variable\n",
    "        \"\"\"\n",
    "        new_col_name = feature1 + feature2 + \"_mean\"\n",
    "        df_enc = (\n",
    "            # select columns\n",
    "            df.loc[:, [feature1, feature2, target]]\n",
    "            # group by feature\n",
    "            .groupby([feature1, feature2])\n",
    "            # aggregate over feature using target mean\n",
    "            .agg(tmp_name = (target, np.mean))\n",
    "            # index (i.e., feature categories) as a column\n",
    "            .reset_index()\n",
    "            # rename the column with the aggregated means\n",
    "            .rename(columns={\"tmp_name\":new_col_name})\n",
    "            )\n",
    "    \n",
    "        # merge: add the new column with the aggregated mean from\n",
    "        # \"df_enc\" back into \"df\"\n",
    "        # df_merged = pd.merge(df, df_enc, how=\"left\", on=[feature1, feature2])\n",
    "    \n",
    "        return df_enc # df_merged\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 397900 entries, 0 to 397899\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   SchoolHoliday      385817 non-null  float64\n",
      " 1   StoreType          397900 non-null  object \n",
      " 2   Assortment         397900 non-null  object \n",
      " 3   Promo2             397900 non-null  int64  \n",
      " 4   Month_mean         397900 non-null  float64\n",
      " 5   Store_mean         397900 non-null  float64\n",
      " 6   DayOfWeek_mean     386039 non-null  float64\n",
      " 7   PromoStore_mean    386000 non-null  float64\n",
      " 8   CD_clip_bins_clip  396864 non-null  float64\n",
      "dtypes: float64(6), int64(1), object(2)\n",
      "memory usage: 27.3+ MB\n"
     ]
    }
   ],
   "source": [
    "caa = CombinedAttributesAdder()\n",
    "new_x = caa.fit_transform(X_y_train)\n",
    "new_x.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SchoolHoliday</td>\n",
       "      <td>0.030367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StoreType</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assortment</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Promo2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Month_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Store_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DayOfWeek_mean</td>\n",
       "      <td>0.029809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PromoStore_mean</td>\n",
       "      <td>0.029907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CD_clip_bins_clip</td>\n",
       "      <td>0.002604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index         0\n",
       "0      SchoolHoliday  0.030367\n",
       "1          StoreType  0.000000\n",
       "2         Assortment  0.000000\n",
       "3             Promo2  0.000000\n",
       "4         Month_mean  0.000000\n",
       "5         Store_mean  0.000000\n",
       "6     DayOfWeek_mean  0.029809\n",
       "7    PromoStore_mean  0.029907\n",
       "8  CD_clip_bins_clip  0.002604"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(new_x.isna().sum() / new_x.shape[0]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical pipeline\n",
    "#\n",
    "# All (except the last) estimators must be transformers (i.e., they\n",
    "# must have a \".fit_transform()\" method).\n",
    "num_pipeline = Pipeline([\n",
    "    # replace NA with mean\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    # standardize the variables: z = (x - mean) / SD\n",
    "    ('std_scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical pipeline\n",
    "#\n",
    "# All (except the last) estimators must be transformers (i.e., they\n",
    "# must have a \".fit_transform()\" method).\n",
    "cat_pipeline = Pipeline([\n",
    "    # replace NA with mode\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    # apply \"OneHotEncoder()\"\n",
    "    ('one_hot', OneHotEncoder(drop='if_binary'))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_num_attribs = [\"SchoolHoliday\", \"Promo2\", \"Month_mean\", \"Store_mean\",\n",
    "                    \"DayOfWeek_mean\", \"PromoStore_mean\", \"CD_clip_bins_clip\"]\n",
    "list_cat_attribs = [\"StoreType\", \"Assortment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColumnTransformer requires tuples with:\n",
    "# - a name\n",
    "# - a transformer\n",
    "# - a list of names (or indices) of columns to which the transformer is applied\n",
    "\n",
    "cols_transformer = ColumnTransformer([\n",
    "    # apply \"num_pipeline\" to numerical columns\n",
    "    ('num', num_pipeline, list_num_attribs),\n",
    "    # apply \"cat_pipeline\" to categorical columns\n",
    "    ('cat', cat_pipeline, list_cat_attribs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([\n",
    "    # transform/add columns\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    # Transform numerical and categorical attributes\n",
    "    (\"cols_transformer\", cols_transformer)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_y_train # include \"Sales\", CombinedAttributesAdder() drops it\n",
    "y_train = X_y_train.loc[:, \"Sales\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Pipeline([\n",
    "    # Pre-processing pipeline\n",
    "    (\"preparation\", full_pipeline),\n",
    "    # Random forest\n",
    "    (\"rf\", RandomForestRegressor(random_state=123))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preparation&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;attribs_adder&#x27;, CombinedAttributesAdder()),\n",
       "                                 (&#x27;cols_transformer&#x27;,\n",
       "                                  ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                    SimpleImputer()),\n",
       "                                                                                   (&#x27;std_scaler&#x27;,\n",
       "                                                                                    StandardScaler())]),\n",
       "                                                                   [&#x27;SchoolHoliday&#x27;,\n",
       "                                                                    &#x27;Promo2&#x27;,\n",
       "                                                                    &#x27;Month_mean&#x27;,\n",
       "                                                                    &#x27;Store_mean&#x27;,\n",
       "                                                                    &#x27;DayOfWeek_mean&#x27;,\n",
       "                                                                    &#x27;PromoStore_mean&#x27;,\n",
       "                                                                    &#x27;CD_clip_bins_clip&#x27;]),\n",
       "                                                                  (&#x27;cat&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                    SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                   (&#x27;one_hot&#x27;,\n",
       "                                                                                    OneHotEncoder(drop=&#x27;if_binary&#x27;))]),\n",
       "                                                                   [&#x27;StoreType&#x27;,\n",
       "                                                                    &#x27;Assortment&#x27;])]))])),\n",
       "                (&#x27;rf&#x27;, RandomForestRegressor(random_state=123))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preparation&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;attribs_adder&#x27;, CombinedAttributesAdder()),\n",
       "                                 (&#x27;cols_transformer&#x27;,\n",
       "                                  ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                    SimpleImputer()),\n",
       "                                                                                   (&#x27;std_scaler&#x27;,\n",
       "                                                                                    StandardScaler())]),\n",
       "                                                                   [&#x27;SchoolHoliday&#x27;,\n",
       "                                                                    &#x27;Promo2&#x27;,\n",
       "                                                                    &#x27;Month_mean&#x27;,\n",
       "                                                                    &#x27;Store_mean&#x27;,\n",
       "                                                                    &#x27;DayOfWeek_mean&#x27;,\n",
       "                                                                    &#x27;PromoStore_mean&#x27;,\n",
       "                                                                    &#x27;CD_clip_bins_clip&#x27;]),\n",
       "                                                                  (&#x27;cat&#x27;,\n",
       "                                                                   Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                    SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                   (&#x27;one_hot&#x27;,\n",
       "                                                                                    OneHotEncoder(drop=&#x27;if_binary&#x27;))]),\n",
       "                                                                   [&#x27;StoreType&#x27;,\n",
       "                                                                    &#x27;Assortment&#x27;])]))])),\n",
       "                (&#x27;rf&#x27;, RandomForestRegressor(random_state=123))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preparation: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;attribs_adder&#x27;, CombinedAttributesAdder()),\n",
       "                (&#x27;cols_transformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;std_scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;SchoolHoliday&#x27;, &#x27;Promo2&#x27;,\n",
       "                                                   &#x27;Month_mean&#x27;, &#x27;Store_mean&#x27;,\n",
       "                                                   &#x27;DayOfWeek_mean&#x27;,\n",
       "                                                   &#x27;PromoStore_mean&#x27;,\n",
       "                                                   &#x27;CD_clip_bins_clip&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;one_hot&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;if_binary&#x27;))]),\n",
       "                                                  [&#x27;StoreType&#x27;,\n",
       "                                                   &#x27;Assortment&#x27;])]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CombinedAttributesAdder</label><div class=\"sk-toggleable__content\"><pre>CombinedAttributesAdder()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cols_transformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;std_scaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;SchoolHoliday&#x27;, &#x27;Promo2&#x27;, &#x27;Month_mean&#x27;,\n",
       "                                  &#x27;Store_mean&#x27;, &#x27;DayOfWeek_mean&#x27;,\n",
       "                                  &#x27;PromoStore_mean&#x27;, &#x27;CD_clip_bins_clip&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;one_hot&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;if_binary&#x27;))]),\n",
       "                                 [&#x27;StoreType&#x27;, &#x27;Assortment&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;SchoolHoliday&#x27;, &#x27;Promo2&#x27;, &#x27;Month_mean&#x27;, &#x27;Store_mean&#x27;, &#x27;DayOfWeek_mean&#x27;, &#x27;PromoStore_mean&#x27;, &#x27;CD_clip_bins_clip&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;StoreType&#x27;, &#x27;Assortment&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;if_binary&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=123)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preparation',\n",
       "                 Pipeline(steps=[('attribs_adder', CombinedAttributesAdder()),\n",
       "                                 ('cols_transformer',\n",
       "                                  ColumnTransformer(transformers=[('num',\n",
       "                                                                   Pipeline(steps=[('imputer',\n",
       "                                                                                    SimpleImputer()),\n",
       "                                                                                   ('std_scaler',\n",
       "                                                                                    StandardScaler())]),\n",
       "                                                                   ['SchoolHoliday',\n",
       "                                                                    'Promo2',\n",
       "                                                                    'Month_mean',\n",
       "                                                                    'Store_mean',\n",
       "                                                                    'DayOfWeek_mean',\n",
       "                                                                    'PromoStore_mean',\n",
       "                                                                    'CD_clip_bins_clip']),\n",
       "                                                                  ('cat',\n",
       "                                                                   Pipeline(steps=[('imputer',\n",
       "                                                                                    SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                   ('one_hot',\n",
       "                                                                                    OneHotEncoder(drop='if_binary'))]),\n",
       "                                                                   ['StoreType',\n",
       "                                                                    'Assortment'])]))])),\n",
       "                ('rf', RandomForestRegressor(random_state=123))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9452213719925228"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "722.3641601276025"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_pred_rf, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "722.3641601276025"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum((y_train -y_pred_rf)**2) / len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (99476, 18)\n",
      "shape X_train: (99476, 17)\n",
      "shape y_train: (99476,)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_path = Path().absolute() / \"data\"\n",
    "filename = \"X_y_test.csv\"\n",
    "X_y_test = load_ds(dataset_path, filename)\n",
    "\n",
    "print(f\"Shape: {X_y_test.shape}\")\n",
    "\n",
    "# X_test = X_y_test.drop(\"Sales\") # include \"Sales\", CombinedAttributesAdder() drops it\n",
    "X_test = X_y_test.drop([\"Sales\"], axis=1)\n",
    "y_test = X_y_test.loc[:, \"Sales\"].copy()\n",
    "\n",
    "print(f\"shape X_train: {X_test.shape}\")\n",
    "print(f\"shape y_train: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(preds, actuals):\n",
    "    assert preds.shape == actuals.shape\n",
    "    return 100 * np.linalg.norm((actuals - preds) / actuals) / np.sqrt(preds.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.812073957516375"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161.8867954288526"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03172699786680336"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSPE(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file, where you ant to store the data\n",
    "file = open('models/random_forest_final', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(rf, file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
